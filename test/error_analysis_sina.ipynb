{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pprint import pprint    # to print the vars of the pathensemble object\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "\n",
    "# Reading\n",
    "from tistools import read_inputfile, get_LMR_interfaces, read_pathensemble, get_weights\n",
    "from tistools import set_tau_distrib, set_tau_first_hit_M_distrib\n",
    "from tistools import collect_tau, collect_tau1, collect_tau2, collect_taum\n",
    "from tistools import ACCFLAGS, REJFLAGS\n",
    "\n",
    "# REPPTIS analysis\n",
    "from tistools import unwrap_by_weight, get_local_probs, get_globall_probs\n",
    "\n",
    "# MSM functions\n",
    "from tistools import construct_M\n",
    "from tistools import mfpt_to_first_last_state, construct_tau_vector\n",
    "from tistools import create_labels_states\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "def pathensembles_nskip(obj, nskip):\n",
    "    keys = [\n",
    "        'cyclenumbers', 'flags', 'generation', 'lambmaxs', 'lambmins',\n",
    "        'lengths', 'lmrs', 'newpathnumbers', 'orders', 'pathnumbers',\n",
    "        'shootlinks', 'weights']\n",
    "    for key in keys:\n",
    "        attr = getattr(obj, key)\n",
    "        setattr(obj, key, attr[:nskip])\n",
    "\n",
    "indir_list = [\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbump2-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbump2-walls/langevin-gamma5/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbump3-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbump3-walls/langevin-gamma5/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosdip2-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosdip2-walls/langevin-gamma5/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/brownian/fine_intf/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/brownian/intf_shift/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/langevin_gamma5/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/langevin_gamma5/fine_intf/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/langevin_gamma5/intf_shift/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosdipmeta-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosdipmeta-walls/langevin_gamma5/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/flat_w-walls/brownian-gamma5/30k-cycles/REPPTIS\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/flat_w-walls/langevin-gamma5/REPPTIS/\",\n",
    "    \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/flat_w-walls/newtonian/REPPTIS/\"\n",
    "    ]\n",
    "\n",
    "for indir in indir_list:\n",
    "    zero_minus_one = False\n",
    "    inputfile = indir + \"/repptis.rst\"    # When using PyRETIS, the input file for REPPTIS simulations is a .rst file\n",
    "    # Move to working directory\n",
    "    os.chdir(indir)\n",
    "    print(os.getcwd())\n",
    "    # Set the ensemble folders and print them\n",
    "    folders = glob.glob(indir + \"/0[0-9][0-9]\")\n",
    "    folders = sorted(folders)\n",
    "\n",
    "    # Reading all input\n",
    "    #===================\n",
    "    interfaces, zero_left, timestep = read_inputfile(inputfile)\n",
    "    LMR_interfaces, LMR_strings = get_LMR_interfaces(interfaces, zero_left)\n",
    "    pathensembles_original = []\n",
    "    for i,fol in enumerate(folders):\n",
    "        pe = read_pathensemble(fol+\"/pathensemble.txt\")\n",
    "        pe.set_name(fol)\n",
    "        pe.set_interfaces([LMR_interfaces[i], LMR_strings[i]])\n",
    "        if i==0:\n",
    "            pe.set_zero_minus_one(zero_minus_one)   # TODO this is never used\n",
    "            pe.set_in_zero_minus(True)\n",
    "        if i==1:\n",
    "            pe.set_in_zero_plus(True)\n",
    "        w, _ = get_weights(pe.flags, ACCFLAGS, REJFLAGS, verbose = False)\n",
    "        pe.set_weights(w)\n",
    "        pathensembles_original.append(pe)\n",
    "\n",
    "        pe.set_orders(load=False, acc_only=True, save=True)        # for the 1st time you run this notebook for a certain simulation, this will store .npy files\n",
    "        # pe.set_orders(load=True, acc_only=True)                  # for the next times, you can read npy files (save=True/False is not important)\n",
    "\n",
    "    stored_values = []\n",
    "    # This loops over the npy file and calculates tau from cycle 100 every 10 cycles\n",
    "    for nskip in range(100, 30010, 10):\n",
    "        pathensembles = copy.deepcopy(pathensembles_original)\n",
    "        for i, pe in enumerate(pathensembles):\n",
    "            pathensembles_nskip(pe,nskip)\n",
    "        # Analysis output is saved to the data dictionary.\n",
    "        data = {}\n",
    "        for i, pe in enumerate(pathensembles):\n",
    "            if i == 0:\n",
    "                data[i] = {}\n",
    "                continue  #  [0-] is not used for Pcross calculations\n",
    "            \n",
    "            # Classify the paths according to their path type.\n",
    "            pathtypes = (\"LML\", \"LMR\", \"RML\", \"RMR\")\n",
    "            pathtype_cycles = {}\n",
    "            for ptype in pathtypes:\n",
    "                pathtype_cycles[ptype] = unwrap_by_weight(\n",
    "                        (pe.lmrs == ptype).astype(int), pe.weights)\n",
    "            \n",
    "            data[i] = {}\n",
    "            plocfull = get_local_probs(pe, tr=False)\n",
    "            data[i][\"full\"] = {}\n",
    "            for ptype in pathtypes:\n",
    "                data[i][\"full\"][ptype] = plocfull[ptype]\n",
    "    \n",
    "        psfull = []\n",
    "        for i in range(1, len(pathensembles)):   # do not use the 0- ensemble\n",
    "            psfull.append({\"LMR\": data[i][\"full\"][\"LMR\"], \n",
    "                    \"RML\": data[i][\"full\"][\"RML\"], \n",
    "                    \"RMR\": data[i][\"full\"][\"RMR\"],\n",
    "                    \"LML\": data[i][\"full\"][\"LML\"]})\n",
    "\n",
    "        Pminfull, Pplusfull, Pcrossfull = get_globall_probs(psfull)\n",
    "\n",
    "        pmps = [data[i][\"full\"][\"LMR\"] for i in range(1,len(pathensembles))]\n",
    "        pmms = [data[i][\"full\"][\"LML\"] for i in range(1,len(pathensembles))]\n",
    "        ppps = [data[i][\"full\"][\"RMR\"] for i in range(1,len(pathensembles))]\n",
    "        ppms = [data[i][\"full\"][\"RML\"] for i in range(1,len(pathensembles))]\n",
    "\n",
    "        N = len(interfaces)\n",
    "        NS = 4*N-5\n",
    "\n",
    "        labels1, labels2 = create_labels_states(N)\n",
    "\n",
    "        if N > 3:  \n",
    "            M = construct_M(pmms, pmps, ppms, ppps, N)\n",
    "        elif N == 3:\n",
    "            M = construct_M_N3(pmms, pmps, ppms, ppps, N)\n",
    "        else:\n",
    "            raise ValueError(\"The amount of interfaces needs to be 3 at least!\")\n",
    "\n",
    "        for i,fol in enumerate(folders):\n",
    "            set_tau_distrib(pathensembles[i])\n",
    "            if True:\n",
    "                set_tau_first_hit_M_distrib(pathensembles[i])\n",
    "\n",
    "        # Compute taus for pathlength analysis\n",
    "        tau_mm, tau_mp, tau_pm, tau_pp = collect_tau(pathensembles)\n",
    "        tau1_mm, tau1_mp, tau1_pm, tau1_pp = collect_tau1(pathensembles)\n",
    "        tau2_mm, tau2_mp, tau2_pm, tau2_pp = collect_tau2(pathensembles)\n",
    "        taum_mm, taum_mp, taum_pm, taum_pp = collect_taum(pathensembles)\n",
    "\n",
    "        tau  = construct_tau_vector(N, NS, tau_mm, tau_mp, tau_pm, tau_pp)\n",
    "        tau1 = construct_tau_vector(N, NS, tau1_mm, tau1_mp, tau1_pm, tau1_pp)\n",
    "        taum = construct_tau_vector(N, NS, taum_mm, taum_mp, taum_pm, taum_pp)\n",
    "        tau2 = construct_tau_vector(N, NS, tau2_mm, tau2_mp, tau2_pm, tau2_pp)\n",
    "        tau_m = tau-tau1-tau2\n",
    "\n",
    "        g1, g2, h1, h2 = mfpt_to_first_last_state(M, tau1, tau_m, tau2)\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"{nskip:5d} cycles, tau {h1[0][0]}\")\n",
    "        stored_values.append(h1[0][0])\n",
    "\n",
    "        # Not sure if we need this, need to check later\n",
    "        del data\n",
    "        del M, N, NS\n",
    "        del tau_mm, tau_mp, tau_pm, tau_pp, tau1_mm, tau1_mp, tau1_pm, tau1_pp\n",
    "        del tau2_mm, tau2_mp, tau2_pm, tau2_pp, taum_mm, taum_mp, taum_pm, taum_pp\n",
    "        del tau, tau1, taum, tau2, tau_m, g1, g2, h1, h2\n",
    "        del pmms, pmps, ppms, ppps\n",
    "\n",
    "    np.save('tau_vs_cycle_interval_10.npy', stored_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyRETIS code for block error analysis\n",
    "    \n",
    "def block_error(data, maxblock=None, blockskip=1):\n",
    "    \"\"\"\n",
    "    Perform block error analysis to estimate the standard deviation in the input data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.array\n",
    "        The data to analyze.\n",
    "    maxblock : int, optional\n",
    "        Maximum block length to consider. Defaults to half the length of the input data.\n",
    "    blockskip : int, optional\n",
    "        Skip factor for block lengths. Defaults to 1 (all block lengths considered).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    blocklen : numpy.array\n",
    "        Array of block lengths considered.\n",
    "    block_avg : numpy.array\n",
    "        Block averages as a function of block length.\n",
    "    block_err : numpy.array\n",
    "        Standard error estimates as a function of block length.\n",
    "    block_err_avg : float\n",
    "        Average error estimate for block lengths greater than maxblock//2.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    maxblock = min(maxblock or n // 2, n // 2)\n",
    "    \n",
    "    blocklen = np.arange(1, maxblock + 1, blockskip, dtype=np.int_)\n",
    "    n_blocks = len(blocklen)\n",
    "    \n",
    "    block = np.zeros(n_blocks)\n",
    "    nblock = np.zeros(n_blocks)\n",
    "    block_avg = np.zeros(n_blocks)\n",
    "    block_var = np.zeros(n_blocks)\n",
    "\n",
    "    for i, val in enumerate(data):\n",
    "        block += val\n",
    "        full_blocks = (i + 1) % blocklen == 0\n",
    "        block[full_blocks] /= blocklen[full_blocks]\n",
    "        nblock[full_blocks] += 1\n",
    "        deltas = block[full_blocks] - block_avg[full_blocks]\n",
    "        block_avg[full_blocks] += deltas / nblock[full_blocks]\n",
    "        block_var[full_blocks] += deltas * (block[full_blocks] - block_avg[full_blocks])\n",
    "        block[full_blocks] = 0.0\n",
    "\n",
    "    block_var /= (nblock - 1)\n",
    "    block_err = np.sqrt(block_var / nblock)\n",
    "    \n",
    "    large_blocks = blocklen > maxblock // 2\n",
    "    block_err_avg = np.mean(block_err[large_blocks])\n",
    "    \n",
    "    return blocklen, block_avg, block_err, block_err_avg, maxblock, n//maxblock\n",
    "\n",
    "\n",
    "def block_error_corr(data, maxblock=None, blockskip=1):\n",
    "    \"\"\"\n",
    "    Run block error analysis and calculate correlation length estimates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.array\n",
    "        Data to analyze.\n",
    "    maxblock : int, optional\n",
    "        Maximum block length to consider. Defaults to half the length of the input data.\n",
    "    blockskip : int, optional\n",
    "        Skip factor for block lengths. Defaults to 1 (all block lengths considered).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    blen : numpy.array\n",
    "        Block lengths considered.\n",
    "    berr : numpy.array\n",
    "        Error estimates as a function of block length.\n",
    "    berr_avg : float\n",
    "        Average error estimate for blocks with length > maxblock // 2.\n",
    "    rel_err : numpy.array\n",
    "        Relative error normalized by the overall average as a function of block length.\n",
    "    avg_rel_err : float\n",
    "        Average relative error for blocks with length > maxblock // 2.\n",
    "    ncor : numpy.array\n",
    "        Estimated correlation length as a function of block length.\n",
    "    avg_ncor : float\n",
    "        Average correlation length for blocks with length > maxblock // 2.\n",
    "    \"\"\"\n",
    "    blen, bavg, berr, berr_avg, max_block_size, min_block_number = block_error(data, maxblock=maxblock, blockskip=blockskip)\n",
    "    rel_err = berr / abs(bavg[0])\n",
    "    avg_rel_err = berr_avg / abs(bavg[0])\n",
    "    ncor = (berr / berr[0])**2\n",
    "    avg_ncor = (berr_avg / berr[0])**2\n",
    "    \n",
    "    return blen, berr, berr_avg, rel_err, avg_rel_err, ncor, avg_ncor, max_block_size, min_block_number\n",
    "\n",
    "indir_list = [\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbump2-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbump2-walls/langevin-gamma5/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbump3-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbump3-walls/langevin-gamma5/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosdip2-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosdip2-walls/langevin-gamma5/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/brownian/fine_intf/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/brownian/intf_shift/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/langevin_gamma5/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/langevin_gamma5/fine_intf/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosbumpmeta-walls/langevin_gamma5/intf_shift/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/cosdipmeta-walls/brownian/REPPTIS/\",\n",
    "    # \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/flat_w-walls/brownian-gamma5/30k-cycles/REPPTIS\",\n",
    "    \"/mnt/tw06_biommeda_pyretis/04.2024_MSM_elias/simulations/flat_w-walls/langevin-gamma5/REPPTIS/\",\n",
    "    ]\n",
    "\n",
    "for indir in indir_list:\n",
    "    os.chdir(indir)\n",
    "    stored_values = np.load('tau_vs_cycle_interval_10.npy')    \n",
    "    stored_values = stored_values[~np.isnan(stored_values)] # remove nans in the beginning\n",
    "    blen, berr, berr_avg, rel_err, avg_rel_err, ncor, avg_ncor, max_block_size, min_block_number = block_error_corr(stored_values,10)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(indir[57:-9])\n",
    "    print(f\"Total Data Points: {len(stored_values)}, max block size: {max_block_size}, min block number: {min_block_number}\")\n",
    "    print(f\"Average Relative Error for blocks > maxblock/2: {avg_rel_err * 100:.1f}%\")\n",
    "    print(f\"Average Correlation Length for Large Blocks: {int(avg_ncor)}\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(rel_err, marker='o', linestyle='-', label = indir[57:-9])\n",
    "    plt.xlabel(\"Block Size\")\n",
    "    plt.ylabel(\"Rlative Error\")\n",
    "    plt.title(f\"Ave Rel Err (blocks > maxblock/2): {avg_rel_err * 100:.1f}%, Block interval 10 cycles\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"Block_Error_Tau.png\", dpi=1000, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}