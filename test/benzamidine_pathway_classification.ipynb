{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e6e93c",
   "metadata": {},
   "source": [
    "# Benzamidine pathway classification (step-by-step)\n",
    "\n",
    "This notebook classifies stitched PPTIS path trajectories of benzamidine unbinding from trypsin into two pathway classes (A or B).\n",
    "\n",
    "**Your system specifics:**\n",
    "- **Pathway A landmarks:** Leu99, Gln175, Gly216\n",
    "- **Pathway B landmarks:** His57, Ser195, Asp102, 60s loop (residues 60-65)\n",
    "- **Key H-bond residue:** Asp189\n",
    "- **Templates:** 2 TRR files for pathway A, 1 TRR file for pathway B\n",
    "- **Stitched trajectories:** 2-3 frames per XTC at 50 ps intervals (extreme downsampling)\n",
    "\n",
    "**Feature extraction:**\n",
    "- Ligand-pocket COM distance\n",
    "- Orientation angle\n",
    "- **Continuous distances** to pathway A residues (3 distances)\n",
    "- **Continuous distances** to pathway B residues (9 distances)\n",
    "- **H-bond count** to Asp189\n",
    "\n",
    "**Classification approach:**\n",
    "- Uses `method='auto'` which selects the best algorithm based on frame count:\n",
    "  - ‚â§3 frames ‚Üí statistics-based (your typical case)\n",
    "  - 4-10 frames ‚Üí voting-based\n",
    "  - >10 frames ‚Üí DTW\n",
    "- **Why continuous distances?** Preserves gradient information crucial for sparse data (2-3 frames)\n",
    "\n",
    "**Workflow:**\n",
    "1. Define pathway residues (already set for your system)\n",
    "2. Load templates (2 pathway A + 1 pathway B)\n",
    "3. Extract features from stitched XTCs\n",
    "4. Classify each trajectory\n",
    "5. Save results to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6621c30",
   "metadata": {},
   "source": [
    "## 1) Imports and basic utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb78055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "# MDAnalysis for trajectory I/O and selections\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.lib.distances import distance_array\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c7e1c",
   "metadata": {},
   "source": [
    "## 2) Small DTW utilities (1D and multivariate)\n",
    "\n",
    "These implementations are straightforward O(N*M) dynamic programming. For moderate-length sequences (hundreds of frames) they are fine. If you need speed, consider `fastdtw` or `dtaidistance` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad476ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_distance_1d(s1, s2, window=None):\n",
    "    # s1, s2: 1D arrays\n",
    "    n, m = len(s1), len(s2)\n",
    "    w = max(n, m) if window is None else int(max(window, abs(n-m)))\n",
    "    dp = np.full((n+1, m+1), np.inf)\n",
    "    dp[0,0] = 0.0\n",
    "    for i in range(1, n+1):\n",
    "        jmin = max(1, i - w)\n",
    "        jmax = min(m, i + w)\n",
    "        for j in range(jmin, jmax+1):\n",
    "            cost = abs(s1[i-1] - s2[j-1])\n",
    "            dp[i,j] = cost + min(dp[i-1,j], dp[i,j-1], dp[i-1,j-1])\n",
    "    return dp[n,m]\n",
    "\n",
    "def dtw_distance_multivariate(X, Y, metric='euclidean', window=None):\n",
    "    # X: T x F, Y: M x F\n",
    "    D = cdist(X, Y, metric=metric)\n",
    "    n, m = D.shape\n",
    "    w = max(n, m) if window is None else int(max(window, abs(n-m)))\n",
    "    dp = np.full((n+1, m+1), np.inf)\n",
    "    dp[0,0] = 0.0\n",
    "    for i in range(1, n+1):\n",
    "        jmin = max(1, i - w)\n",
    "        jmax = min(m, i + w)\n",
    "        for j in range(jmin, jmax+1):\n",
    "            cost = D[i-1, j-1]\n",
    "            dp[i,j] = cost + min(dp[i-1,j], dp[i,j-1], dp[i-1,j-1])\n",
    "    return dp[n,m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f21eb6",
   "metadata": {},
   "source": [
    "## 4) Feature extraction from a trajectory\n",
    "We'll compute a small, robust feature set per frame: (1) ligand-pocket COM distance, (2) a small contact fingerprint between ligand and a set of pocket/channel residues, (3) a simple orientation proxy (angle). These are compact and usually survive downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54775a75",
   "metadata": {},
   "source": [
    "## 4a) Define pathway-specific residues (landmarks)\n",
    "For each pathway, define residue lists that characterize the path. These are typically residues lining the channel or gate regions that distinguish pathway A from B. The feature extractor will compute minimum distances from ligand to each residue cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7833f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathway A residues: [99, 175, 216]\n",
      "Pathway B residues: [57, 195, 102, 60, 61, 62, 63, 64, 65]\n",
      "H-bond donor/acceptor: Asp189\n"
     ]
    }
   ],
   "source": [
    "# Define pathway-specific residues based on structural analysis\n",
    "#Benzamidine unbinding from trypsin\n",
    "\n",
    "# Pathway A residues (defining landmarks)\n",
    "pathway_A_residues = [\n",
    "    99,   # Leu99\n",
    "    175,  # Gln175\n",
    "    216   # Gly216\n",
    "]\n",
    "\n",
    "# Pathway B residues (defining landmarks)\n",
    "pathway_B_residues = [\n",
    "    57,   # His57\n",
    "    195,  # Ser195\n",
    "    102,  # Asp102\n",
    "    # 60s loop residues\n",
    "    60, 61, 62, 63, 64, 65\n",
    "]\n",
    "\n",
    "# Key residue for H-bond analysis\n",
    "asp189_resid = 189  # Asp189 - important for H-bonding\n",
    "\n",
    "print(f\"Pathway A residues: {pathway_A_residues}\")\n",
    "print(f\"Pathway B residues: {pathway_B_residues}\")\n",
    "print(f\"H-bond donor/acceptor: Asp{asp189_resid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd71749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector composition:\n",
      "==================================================\n",
      "1. Ligand-pocket COM distance:    1 feature\n",
      "2. Orientation angle:             1 feature\n",
      "3. Distances to pathway A:        3 features (Leu99, Gln175, Gly216)\n",
      "4. Distances to pathway B:        9 features (His57, Ser195, Asp102, 60s loop)\n",
      "5. H-bonds to Asp189:             1 feature\n",
      "--------------------------------------------------\n",
      "Total features per frame:         15\n",
      "\n",
      "For 2-3 frame trajectories, feature matrix shape: (2-3, 14)\n",
      "This gives ~28-42 data points total for classification\n"
     ]
    }
   ],
   "source": [
    "# Verify feature dimensions for your system\n",
    "print(\"Feature vector composition:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"1. Ligand-pocket COM distance:    1 feature\")\n",
    "print(f\"2. Orientation angle:             1 feature\")\n",
    "print(f\"3. Distances to pathway A:        {len(pathway_A_residues)} features (Leu99, Gln175, Gly216)\")\n",
    "print(f\"4. Distances to pathway B:        {len(pathway_B_residues)} features (His57, Ser195, Asp102, 60s loop)\")\n",
    "print(f\"5. H-bonds to Asp189:             1 feature\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total features per frame:         {2 + len(pathway_A_residues) + len(pathway_B_residues) + 1}\")\n",
    "print()\n",
    "print(\"For 2-3 frame trajectories, feature matrix shape: (2-3, 14)\")\n",
    "print(\"This gives ~28-42 data points total for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f38f7",
   "metadata": {},
   "source": [
    "## 4b) H-bond detection: Distance + Angle vs Distance-only\n",
    "\n",
    "**Why distance alone is insufficient:**\n",
    "- Many atom pairs can be within 3.5 √Ö without forming an H-bond\n",
    "- True H-bonds have directionality: the D-H¬∑¬∑¬∑A angle should be ~180¬∞ (linear)\n",
    "- Distance-only detection gives false positives from non-bonding contacts\n",
    "\n",
    "**Proper H-bond geometry:**\n",
    "1. **Distance criterion**: D-H¬∑¬∑¬∑A distance < 3.5 √Ö (0.35 nm)\n",
    "2. **Angle criterion**: D-H¬∑¬∑¬∑A angle > 120-150¬∞ (measures linearity)\n",
    "   - 180¬∞ = perfectly linear (ideal)\n",
    "   - 120¬∞ = minimum for H-bond character\n",
    "   - < 120¬∞ = likely just a contact, not an H-bond\n",
    "\n",
    "**Implementation approaches:**\n",
    "\n",
    "1. **With explicit hydrogens (BEST)** ‚≠ê\n",
    "   - Locate H atoms bonded to donor heavy atoms (N, O)\n",
    "   - Measure D-H¬∑¬∑¬∑A angle directly\n",
    "   - Most accurate but requires hydrogens in structure\n",
    "   - Used by MDAnalysis.analysis.hydrogenbonds.HydrogenBondAnalysis\n",
    "\n",
    "2. **Without explicit hydrogens (FALLBACK)**\n",
    "   - Use heavy atom distance D¬∑¬∑¬∑A only\n",
    "   - Less accurate but works with reduced structures\n",
    "   - Assumes ideal geometry\n",
    "   - Current implementation tries explicit H first, falls back to distance-only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faea827",
   "metadata": {},
   "source": [
    "## 4c) Note on time vs frame indexing\n",
    "\n",
    "**Why we use frame indices instead of time values:**\n",
    "\n",
    "For stitched PPTIS trajectories concatenated from multiple segments (trajB + trajF):\n",
    "- **Time values are discontinuous**: Each segment comes from a separate simulation with its own time origin\n",
    "- **Time values may overlap**: trajB and trajF can have conflicting time stamps\n",
    "- **Frame indices are consistent**: Sequential frame numbers (0, 1, 2, ...) work reliably regardless of source\n",
    "\n",
    "**Example issue with time indexing:**\n",
    "```\n",
    "Segment 1 (trajB): frames at t = 100, 150, 200 ps\n",
    "Segment 2 (trajF): frames at t = 50, 100, 150 ps\n",
    "Stitched XTC:      frames 0, 1, 2, 3, 4, 5 (consistent)\n",
    "                   times = 100, 150, 200, 50, 100, 150 ps (discontinuous!)\n",
    "```\n",
    "\n",
    "**Solution:** Use `ts.frame` (0-based frame index) instead of `ts.time` (simulation time in ps)\n",
    "\n",
    "This only affects plotting/visualization - features are extracted per-frame and classification works identically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f91ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(universe, ligand_sel='resname BEN', pocket_sel='resid 190, 191, 192, 195, 213, 215, 216, 219, 220, 224, 228, 247 and protein',\n",
    "                     pathway_A_resids=None, pathway_B_resids=None, \n",
    "                     hbond_resid=189, hbond_distance=0.35, hbond_angle=120):\n",
    "    \"\"\"\n",
    "    Extract features from trajectory for pathway classification.\n",
    "    \n",
    "    Features include:\n",
    "    1. Ligand-pocket COM distance\n",
    "    2. Orientation angle (ligand->pocket vector vs reference axis)\n",
    "    3. Minimum distances to pathway A landmark residues (continuous)\n",
    "    4. Minimum distances to pathway B landmark residues (continuous)\n",
    "    5. Number of H-bonds between ligand and specified residue (e.g., Asp189)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    universe : MDAnalysis.Universe\n",
    "    ligand_sel : str, ligand selection string\n",
    "    pocket_sel : str, pocket selection string\n",
    "    pathway_A_resids : list of int, pathway A landmark residues\n",
    "    pathway_B_resids : list of int, pathway B landmark residues\n",
    "    hbond_resid : int, residue for H-bond counting (default 189 for Asp189)\n",
    "    hbond_distance : float, H-bond distance cutoff in nm (default 0.35 = 3.5 √Ö)\n",
    "    hbond_angle : float, H-bond angle cutoff in degrees (default 120¬∞)\n",
    "                         measures D-H¬∑¬∑¬∑A angle where 180¬∞ is perfectly linear\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    frames : array, frame indices (0-based) for each frame\n",
    "             Note: uses frame index instead of time because stitched XTCs from \n",
    "             concatenated segments have inconsistent/discontinuous time values\n",
    "    feats : array (T x F), feature matrix where each row is a frame\n",
    "    \"\"\"\n",
    "    lig = universe.select_atoms(ligand_sel)\n",
    "    pocket = universe.select_atoms(pocket_sel)\n",
    "    \n",
    "    # H-bond partner residue (e.g., Asp189)\n",
    "    hbond_res = universe.select_atoms(f'resid {hbond_resid} and protein')\n",
    "    \n",
    "    # Pathway landmark residues - use distances not binary contacts\n",
    "    pathA_groups = []\n",
    "    if pathway_A_resids:\n",
    "        for resid in pathway_A_resids:\n",
    "            sel = universe.select_atoms(f'resid {resid} and protein')\n",
    "            if len(sel) > 0:\n",
    "                pathA_groups.append(sel)\n",
    "    \n",
    "    pathB_groups = []\n",
    "    if pathway_B_resids:\n",
    "        for resid in pathway_B_resids:\n",
    "            sel = universe.select_atoms(f'resid {resid} and protein')\n",
    "            if len(sel) > 0:\n",
    "                pathB_groups.append(sel)\n",
    "    \n",
    "    times = []\n",
    "    feats = []\n",
    "    \n",
    "    for ts in universe.trajectory:\n",
    "        # Use frame index instead of time (times are unreliable for concatenated segments)\n",
    "        times.append(ts.frame)\n",
    "        lig_com = lig.center_of_mass()\n",
    "        pocket_com = pocket.center_of_mass()\n",
    "        d_com = np.linalg.norm(lig_com - pocket_com)\n",
    "        \n",
    "        # Orientation angle: vector ligand->pocket vs reference axis\n",
    "        axis = np.array([1.0, 0.0, 0.0])\n",
    "        v = (pocket_com - lig_com)\n",
    "        normv = np.linalg.norm(v) if np.linalg.norm(v) > 0 else 1.0\n",
    "        angle = math.acos(np.clip(np.dot(v, axis) / (normv * np.linalg.norm(axis)), -1.0, 1.0))\n",
    "        \n",
    "        # Distance to pathway landmark residues (continuous, in nm)\n",
    "        def distances_to(res_groups):\n",
    "            dists = []\n",
    "            for grp in res_groups:\n",
    "                if len(grp) == 0:\n",
    "                    dists.append(999.0)  # large distance for missing residues\n",
    "                    continue\n",
    "                D = distance_array(lig.positions, grp.positions)\n",
    "                minD = D.min() if D.size else 999.0\n",
    "                dists.append(minD)\n",
    "            return np.array(dists, dtype=float)\n",
    "        \n",
    "        dA = distances_to(pathA_groups)\n",
    "        dB = distances_to(pathB_groups)\n",
    "        \n",
    "        # H-bond counting with proper geometric criteria (distance + angle)\n",
    "        n_hbonds = 0\n",
    "        if len(hbond_res) > 0 and len(lig) > 0:\n",
    "            # Select potential donors and acceptors with explicit hydrogens\n",
    "            # Ligand donors: N-H or O-H groups\n",
    "            lig_donors_heavy = lig.select_atoms('(name N* or name O*) and not name H*')\n",
    "            lig_acceptors = lig.select_atoms('name N* or name O*')\n",
    "            \n",
    "            # Residue groups (Asp189 has carboxyl oxygens as acceptors, can also be donors)\n",
    "            res_donors_heavy = hbond_res.select_atoms('(name N* or name O*) and not name H*')\n",
    "            res_acceptors = hbond_res.select_atoms('name N* or name O*')\n",
    "            \n",
    "            # Try to find hydrogens bonded to heavy atoms\n",
    "            try:\n",
    "                lig_hydrogens = lig.select_atoms('name H*')\n",
    "                res_hydrogens = hbond_res.select_atoms('name H*')\n",
    "                has_hydrogens = len(lig_hydrogens) > 0 or len(res_hydrogens) > 0\n",
    "            except:\n",
    "                has_hydrogens = False\n",
    "            \n",
    "            if has_hydrogens:\n",
    "                # Method 1: Use explicit hydrogens (more accurate)\n",
    "                # Check ligand as donor -> residue as acceptor\n",
    "                for donor_heavy in lig_donors_heavy:\n",
    "                    # Find hydrogens bonded to this donor (within 0.12 nm)\n",
    "                    D_DH = distance_array(donor_heavy.position.reshape(1,-1), lig_hydrogens.positions)\n",
    "                    bonded_H_idx = np.where(D_DH[0] < 1.2)[0]  # 0.12 nm = 1.2 √Ö\n",
    "                    \n",
    "                    for h_idx in bonded_H_idx:\n",
    "                        h_pos = lig_hydrogens[h_idx].position\n",
    "                        # Check distance H¬∑¬∑¬∑A\n",
    "                        D_HA = np.linalg.norm(res_acceptors.positions - h_pos.reshape(1,-1), axis=1)\n",
    "                        close_acceptors = np.where(D_HA < hbond_distance * 10)[0]  # convert nm to √Ö\n",
    "                        \n",
    "                        for acc_idx in close_acceptors:\n",
    "                            # Calculate D-H¬∑¬∑¬∑A angle\n",
    "                            vec_DH = h_pos - donor_heavy.position\n",
    "                            vec_HA = res_acceptors[acc_idx].position - h_pos\n",
    "                            \n",
    "                            cos_angle = np.dot(vec_DH, vec_HA) / (np.linalg.norm(vec_DH) * np.linalg.norm(vec_HA) + 1e-10)\n",
    "                            angle_deg = np.degrees(np.arccos(np.clip(cos_angle, -1, 1)))\n",
    "                            \n",
    "                            if angle_deg >= hbond_angle:\n",
    "                                n_hbonds += 1\n",
    "                \n",
    "                # Check residue as donor -> ligand as acceptor\n",
    "                for donor_heavy in res_donors_heavy:\n",
    "                    D_DH = distance_array(donor_heavy.position.reshape(1,-1), res_hydrogens.positions)\n",
    "                    bonded_H_idx = np.where(D_DH[0] < 1.2)[0]\n",
    "                    \n",
    "                    for h_idx in bonded_H_idx:\n",
    "                        h_pos = res_hydrogens[h_idx].position\n",
    "                        D_HA = np.linalg.norm(lig_acceptors.positions - h_pos.reshape(1,-1), axis=1)\n",
    "                        close_acceptors = np.where(D_HA < hbond_distance * 10)[0]\n",
    "                        \n",
    "                        for acc_idx in close_acceptors:\n",
    "                            vec_DH = h_pos - donor_heavy.position\n",
    "                            vec_HA = lig_acceptors[acc_idx].position - h_pos\n",
    "                            \n",
    "                            cos_angle = np.dot(vec_DH, vec_HA) / (np.linalg.norm(vec_DH) * np.linalg.norm(vec_HA) + 1e-10)\n",
    "                            angle_deg = np.degrees(np.arccos(np.clip(cos_angle, -1, 1)))\n",
    "                            \n",
    "                            if angle_deg >= hbond_angle:\n",
    "                                n_hbonds += 1\n",
    "            else:\n",
    "                # Method 2: No explicit hydrogens - use heavy atom approximation\n",
    "                # Assume hydrogen is along D-A axis (less accurate but works without H)\n",
    "                # Check all donor-acceptor pairs\n",
    "                if len(lig_donors_heavy) > 0 and len(res_acceptors) > 0:\n",
    "                    D = distance_array(lig_donors_heavy.positions, res_acceptors.positions)\n",
    "                    # Count pairs within distance cutoff\n",
    "                    n_hbonds += np.sum(D < hbond_distance * 10)  # convert nm to √Ö\n",
    "                \n",
    "                if len(res_donors_heavy) > 0 and len(lig_acceptors) > 0:\n",
    "                    D = distance_array(res_donors_heavy.positions, lig_acceptors.positions)\n",
    "                    n_hbonds += np.sum(D < hbond_distance * 10)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        # Order: [COM_dist, angle, distances_to_A, distances_to_B, n_hbonds]\n",
    "        feat = np.concatenate([[d_com, angle], dA, dB, [n_hbonds]])\n",
    "        feats.append(feat)\n",
    "    \n",
    "    feats = np.vstack(feats) if len(feats) else np.empty((0,0))\n",
    "    return np.array(times), feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de9cd4",
   "metadata": {},
   "source": [
    "## 5) Load templates (path A / B) and build reference feature sequences\n",
    "Provide paths to representative template XTCs (these could be higher-frequency original runs). We'll compute features for each template and keep them as sequences for DTW matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bacc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading template: /run/user/1001/gvfs/sftp:host=172.18.15.4,user=elias/mnt/external/init_paths/load/915/915.xtc\n"
     ]
    }
   ],
   "source": [
    "# Template file paths - update these to your actual template files\n",
    "template_top = '/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/trypsin-benzos/gromacs_input_latest/conf.gro'  # topology file (use local copy if GVFS)\n",
    "\n",
    "# You have 2 templates for pathway A and 1 for pathway B\n",
    "template_A1_xtc = '/run/user/1001/gvfs/sftp:host=172.18.15.4,user=elias/mnt/external/init_paths/load/915/915.xtc'  # pathway A template 1\n",
    "template_A2_xtc = '/run/user/1001/gvfs/sftp:host=172.18.15.4,user=elias/mnt/external/init_paths/load/948/948.xtc'  # pathway A template 2\n",
    "template_B_xtc = '/run/user/1001/gvfs/sftp:host=172.18.15.4,user=elias/mnt/external/init_paths/load/967/967.xtc'    # pathway B template\n",
    "\n",
    "# Load template features\n",
    "def load_template_features(top, traj, ligand_sel='resname BEN', pocket_sel=None, \n",
    "                          pathwayA=None, pathwayB=None, hbond_resid=189):\n",
    "    \"\"\"Load and extract features from a template trajectory.\"\"\"\n",
    "    if not (os.path.exists(top) and os.path.exists(traj)):\n",
    "        raise FileNotFoundError(f'Missing template files: {top} or {traj}')\n",
    "    print(f'Loading template: {traj}')\n",
    "    u = mda.Universe(top, traj)\n",
    "    tsel = pocket_sel or 'resid 189 190 215 216 218 and protein'\n",
    "    print(f'Using pocket selection: {tsel}')\n",
    "    frames, feats = extract_features(u, ligand_sel=ligand_sel, pocket_sel=tsel, \n",
    "                                   pathway_A_resids=pathwayA, pathway_B_resids=pathwayB,\n",
    "                                   hbond_resid=hbond_resid)\n",
    "    return frames, feats\n",
    "\n",
    "# Load all templates - uncomment and run when files are ready\n",
    "# Make sure pathway_A_residues and pathway_B_residues are defined first\n",
    "tA1_times, tA1_feats = load_template_features(template_top, template_A1_xtc, \n",
    "                                               pathwayA=pathway_A_residues, pathwayB=pathway_B_residues)\n",
    "tA2_times, tA2_feats = load_template_features(template_top, template_A2_xtc,\n",
    "                                               pathwayA=pathway_A_residues, pathwayB=pathway_B_residues)\n",
    "tB_times, tB_feats = load_template_features(template_top, template_B_xtc,\n",
    "                                             pathwayA=pathway_A_residues, pathwayB=pathway_B_residues)\n",
    "\n",
    "# Combine pathway A templates by concatenating (increases template diversity)\n",
    "# Note: tA1_times, tA2_times, tA_times are actually frame indices (0-based), not time values\n",
    "tA_feats = np.vstack([tA1_feats, tA2_feats])\n",
    "tA_times = np.concatenate([tA1_times, tA2_times])\n",
    "\n",
    "print(\"Template loading instructions:\")\n",
    "print(\"1. Update template file paths above with actual .trr file locations\")\n",
    "print(\"2. Uncomment the loading code\")\n",
    "print(\"3. Run this cell to load tA_feats (combined A1+A2) and tB_feats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc74cd",
   "metadata": {},
   "source": [
    "## 6) Classification function\n",
    "We provide two classification routes: (A) DTW on multivariate features (works without interpolation), (B) resample to common time grid and compare using DTW or L2. We'll also include the softmin scoring approach (soft-fuzzy assignment)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab63619",
   "metadata": {},
   "source": [
    "## 5a) Scoring methods overview\n",
    "\n",
    "**Currently implemented methods:**\n",
    "\n",
    "1. **DTW (Dynamic Time Warping) - multivariate**\n",
    "   - Compares feature trajectories allowing for time warping/stretching\n",
    "   - Robust to different sampling rates and speeds\n",
    "   - Returns distance to each template; assigns label based on minimum\n",
    "   - Window parameter controls allowed warping (smaller = faster but less flexible)\n",
    "\n",
    "2. **Softmin scoring (fuzzy assignment)**\n",
    "   - Computes per-frame soft-minimum distance to template using log-sum-exp\n",
    "   - Averages across trajectory for global score\n",
    "   - More robust to outlier frames than hard assignment\n",
    "   - Œª parameter controls \"softness\" (smaller = softer, more fuzzy)\n",
    "\n",
    "**Alternative methods you can implement:**\n",
    "\n",
    "3. **Hausdorff distance**\n",
    "   - Measures maximum deviation between two sets\n",
    "   - Good for detecting worst-case differences\n",
    "   - Implementation: `from scipy.spatial.distance import directed_hausdorff`\n",
    "\n",
    "4. **Fr√©chet distance (discrete)**\n",
    "   - \"Dog-leash\" distance - measures similarity with monotonic matching\n",
    "   - Better for ordered trajectories than Hausdorff\n",
    "   - Available in packages like `similaritymeasures`\n",
    "\n",
    "5. **Hidden Markov Models (HMMs)**\n",
    "   - Model each pathway as an HMM trained on template data\n",
    "   - Classify by computing likelihood under each model\n",
    "   - Use `hmmlearn` package\n",
    "\n",
    "6. **Simple Euclidean after alignment**\n",
    "   - Interpolate both to same time grid, compute L2 distance\n",
    "   - Fast but requires good time alignment\n",
    "   - Best when sampling rates are similar\n",
    "\n",
    "7. **Path signature methods**\n",
    "   - Use rough path theory / signature transform\n",
    "   - Captures geometric properties independent of parameterization\n",
    "   - See `esig` or `signatory` packages\n",
    "\n",
    "8. **Neural network embeddings**\n",
    "   - Train autoencoder/VAE on template paths\n",
    "   - Classify in latent space\n",
    "   - Best when you have many labeled examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d0360",
   "metadata": {},
   "source": [
    "## 5b) Dealing with extreme downsampling (2-3 frames per trajectory)\n",
    "\n",
    "**Your situation:** Stitched XTCs have 2-3 frames at 50 ps intervals, while full trajectories have frames every 20 fs.\n",
    "- Downsampling factor: ~2500x (50 ps / 0.02 ps)\n",
    "- Available points per trajectory: 2-3 frames\n",
    "- This is **too sparse for DTW** to capture trajectory dynamics meaningfully\n",
    "\n",
    "**Why DTW struggles here:**\n",
    "- DTW needs sufficient sampling to capture trajectory shape/dynamics\n",
    "- With only 2-3 points, you're essentially comparing discrete \"snapshots\" rather than paths\n",
    "- The warping flexibility of DTW provides no benefit with so few points\n",
    "- Computational cost of DTW is wasted on 2-3 point comparisons\n",
    "\n",
    "**Recommended alternatives for sparse data:**\n",
    "\n",
    "1. **Simple feature statistics (BEST for 2-3 frames)** ‚≠ê\n",
    "   - Compute mean/min/max of each feature across the 2-3 frames\n",
    "   - Compare summary statistics to template statistics using simple distance\n",
    "   - Fast, interpretable, and appropriate for sparse data\n",
    "   - Example: mean ligand-pocket distance, min distance to pathway A residues, etc.\n",
    "\n",
    "2. **Direct frame-to-template matching**\n",
    "   - For each of your 2-3 frames, find nearest frame in template\n",
    "   - Average the distances across your frames\n",
    "   - Essentially k-NN in feature space\n",
    "   - Better than DTW when trajectory order doesn't matter\n",
    "\n",
    "3. **Endpoint analysis**\n",
    "   - Focus on initial and final states (frame 1 and frame 2-3)\n",
    "   - Compare start/end feature vectors to pathway templates\n",
    "   - Logical for PPTIS where fragments represent transitions\n",
    "\n",
    "4. **Voting/ensemble approach**\n",
    "   - Classify each individual frame independently\n",
    "   - Final label = majority vote across 2-3 frames\n",
    "   - More robust to single outlier frames\n",
    "\n",
    "**What to avoid:**\n",
    "- ‚ùå DTW (overkill and misleading for 2-3 points)\n",
    "- ‚ùå Interpolation (creates artificial data between sparse points)\n",
    "- ‚ùå Softmin with trajectory averaging (loses frame-level information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e151a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementations for sparse trajectory classification (2-3 frames)\n",
    "\n",
    "def classify_sparse_statistics(feats, templateA_feats, templateB_feats):\n",
    "    \"\"\"\n",
    "    Best for 2-3 frame trajectories. Compares feature statistics.\n",
    "    \n",
    "    Computes mean across trajectory frames and compares to template means.\n",
    "    \"\"\"\n",
    "    # Summary statistics for segment\n",
    "    seg_mean = feats.mean(axis=0)\n",
    "    seg_std = feats.std(axis=0) if len(feats) > 1 else np.zeros_like(seg_mean)\n",
    "    \n",
    "    # Template statistics\n",
    "    tA_mean = templateA_feats.mean(axis=0)\n",
    "    tB_mean = templateB_feats.mean(axis=0)\n",
    "    \n",
    "    # Distance to template means (weighted by inverse template variance for robustness)\n",
    "    tA_std = templateA_feats.std(axis=0) + 1e-6\n",
    "    tB_std = templateB_feats.std(axis=0) + 1e-6\n",
    "    \n",
    "    # Mahalanobis-like distance (weighted by template variance)\n",
    "    dA = np.sqrt(np.sum(((seg_mean - tA_mean) / tA_std) ** 2))\n",
    "    dB = np.sqrt(np.sum(((seg_mean - tB_mean) / tB_std) ** 2))\n",
    "    \n",
    "    label = 'A' if dA < dB else 'B'\n",
    "    margin = abs(dA - dB)\n",
    "    confidence = margin / (dA + dB + 1e-12)\n",
    "    \n",
    "    return label, confidence, dA, dB\n",
    "\n",
    "def classify_frame_voting(feats, templateA_feats, templateB_feats):\n",
    "    \"\"\"\n",
    "    Classify each frame independently, then vote. Good for 2-3 frames.\n",
    "    \"\"\"\n",
    "    votes = []\n",
    "    distances_A = []\n",
    "    distances_B = []\n",
    "    \n",
    "    for frame_feat in feats:\n",
    "        # Find distance to nearest template frame\n",
    "        dA = np.min(np.linalg.norm(templateA_feats - frame_feat, axis=1))\n",
    "        dB = np.min(np.linalg.norm(templateB_feats - frame_feat, axis=1))\n",
    "        \n",
    "        distances_A.append(dA)\n",
    "        distances_B.append(dB)\n",
    "        votes.append('A' if dA < dB else 'B')\n",
    "    \n",
    "    # Majority vote\n",
    "    vote_A = votes.count('A')\n",
    "    vote_B = votes.count('B')\n",
    "    label = 'A' if vote_A > vote_B else ('B' if vote_B > vote_A else 'Uncertain')\n",
    "    \n",
    "    # Average distances\n",
    "    avg_dA = np.mean(distances_A)\n",
    "    avg_dB = np.mean(distances_B)\n",
    "    confidence = abs(vote_A - vote_B) / len(votes)\n",
    "    \n",
    "    return label, confidence, avg_dA, avg_dB\n",
    "\n",
    "def classify_endpoint_analysis(feats, templateA_feats, templateB_feats):\n",
    "    \"\"\"\n",
    "    Focus on start and end frames. Good for PPTIS transition fragments.\n",
    "    \"\"\"\n",
    "    if len(feats) < 2:\n",
    "        # Single frame - compare to template means\n",
    "        return classify_sparse_statistics(feats, templateA_feats, templateB_feats)\n",
    "    \n",
    "    start_frame = feats[0]\n",
    "    end_frame = feats[-1]\n",
    "    \n",
    "    # Distance of start frame to template starts\n",
    "    tA_start_dist = np.min(np.linalg.norm(templateA_feats[:10] - start_frame, axis=1))\n",
    "    tB_start_dist = np.min(np.linalg.norm(templateB_feats[:10] - start_frame, axis=1))\n",
    "    \n",
    "    # Distance of end frame to template ends\n",
    "    tA_end_dist = np.min(np.linalg.norm(templateA_feats[-10:] - end_frame, axis=1))\n",
    "    tB_end_dist = np.min(np.linalg.norm(templateB_feats[-10:] - end_frame, axis=1))\n",
    "    \n",
    "    # Combined score (weighted average)\n",
    "    dA = 0.5 * tA_start_dist + 0.5 * tA_end_dist\n",
    "    dB = 0.5 * tB_start_dist + 0.5 * tB_end_dist\n",
    "    \n",
    "    label = 'A' if dA < dB else 'B'\n",
    "    margin = abs(dA - dB)\n",
    "    confidence = margin / (dA + dB + 1e-12)\n",
    "    \n",
    "    return label, confidence, dA, dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa362bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example implementations of alternative scoring methods\n",
    "\n",
    "def hausdorff_distance(X, Y):\n",
    "    \"\"\"Hausdorff distance between two trajectories (max-min distance)\"\"\"\n",
    "    from scipy.spatial.distance import directed_hausdorff\n",
    "    d_XY = directed_hausdorff(X, Y)[0]\n",
    "    d_YX = directed_hausdorff(Y, X)[0]\n",
    "    return max(d_XY, d_YX)\n",
    "\n",
    "def frechet_distance(X, Y):\n",
    "    \"\"\"Discrete Fr√©chet distance (requires similaritymeasures package)\"\"\"\n",
    "    try:\n",
    "        from similaritymeasures import frechet_dist\n",
    "        return frechet_dist(X, Y)\n",
    "    except ImportError:\n",
    "        print(\"Install: pip install similaritymeasures\")\n",
    "        return None\n",
    "\n",
    "def euclidean_after_interpolation(times1, X, times2, Y):\n",
    "    \"\"\"Interpolate to common grid and compute L2 distance\"\"\"\n",
    "    from scipy.interpolate import interp1d\n",
    "    # Find common time range\n",
    "    t_min = max(times1.min(), times2.min())\n",
    "    t_max = min(times1.max(), times2.max())\n",
    "    t_common = np.linspace(t_min, t_max, 100)\n",
    "    # Interpolate\n",
    "    X_interp = np.vstack([interp1d(times1, X[:,i], bounds_error=False, fill_value='extrapolate')(t_common)\n",
    "                          for i in range(X.shape[1])]).T\n",
    "    Y_interp = np.vstack([interp1d(times2, Y[:,i], bounds_error=False, fill_value='extrapolate')(t_common)\n",
    "                          for i in range(Y.shape[1])]).T\n",
    "    return np.linalg.norm(X_interp - Y_interp)\n",
    "\n",
    "# These are optional - uncomment to use in classify_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "becf37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmin_z(X, path_feats, lam=1.0):\n",
    "    # X: T x F, path_feats: M x F\n",
    "    D2 = cdist(X, path_feats, metric='sqeuclidean')  # T x M\n",
    "    # per-frame soft-min (log-sum-exp of negative distances)\n",
    "    z_per_frame = - (1.0/lam) * np.log(np.exp(-lam * D2).sum(axis=1))\n",
    "    return z_per_frame\n",
    "\n",
    "def classify_segment(feats, templateA_feats, templateB_feats, method='auto', window=None, lam=1.0, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Classify a trajectory segment against two templates.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    feats : array (T x F) - trajectory features to classify\n",
    "    templateA_feats : array (M_A x F) - pathway A template features\n",
    "    templateB_feats : array (M_B x F) - pathway B template features\n",
    "    method : str - classification method:\n",
    "        'auto' : automatically choose based on trajectory length (default)\n",
    "        'statistics' : compare feature means (best for 2-3 frames)\n",
    "        'voting' : per-frame nearest neighbor voting (good for 2-3 frames)\n",
    "        'endpoint' : compare start/end states (good for PPTIS fragments)\n",
    "        'dtw' : Dynamic Time Warping (only good for >10 frames)\n",
    "        'softmin' : soft-minimum scoring (only good for >10 frames)\n",
    "    window : int - DTW window size (only used for method='dtw')\n",
    "    lam : float - softmin lambda parameter (only used for method='softmin')\n",
    "    eps : float - threshold for uncertain classification\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    label : str - 'A', 'B', or 'Uncertain'\n",
    "    confidence : float - confidence score\n",
    "    dA : float - distance/score to template A\n",
    "    dB : float - distance/score to template B\n",
    "    \"\"\"\n",
    "    T = len(feats)\n",
    "    \n",
    "    # Auto-select method based on trajectory length\n",
    "    if method == 'auto':\n",
    "        if T <= 3:\n",
    "            method = 'statistics'  # Best for very sparse data\n",
    "        elif T <= 10:\n",
    "            method = 'voting'  # Good for sparse data\n",
    "        else:\n",
    "            method = 'dtw'  # Use DTW for longer trajectories\n",
    "    \n",
    "    # Sparse data methods (2-10 frames)\n",
    "    if method == 'statistics':\n",
    "        return classify_sparse_statistics(feats, templateA_feats, templateB_feats)\n",
    "    elif method == 'voting':\n",
    "        return classify_frame_voting(feats, templateA_feats, templateB_feats)\n",
    "    elif method == 'endpoint':\n",
    "        return classify_endpoint_analysis(feats, templateA_feats, templateB_feats)\n",
    "    \n",
    "    # Dense trajectory methods (>10 frames)\n",
    "    elif method == 'dtw':\n",
    "        dA = dtw_distance_multivariate(feats, templateA_feats, window=window)\n",
    "        dB = dtw_distance_multivariate(feats, templateB_feats, window=window)\n",
    "        label = 'A' if dA < dB else 'B'\n",
    "        margin = abs(dA - dB)\n",
    "        if margin < eps:\n",
    "            label = 'Uncertain'\n",
    "        confidence = margin / (dA + dB + 1e-12)\n",
    "        return label, confidence, dA, dB\n",
    "    \n",
    "    elif method == 'softmin':\n",
    "        zA = softmin_z(feats, templateA_feats, lam=lam)\n",
    "        zB = softmin_z(feats, templateB_feats, lam=lam)\n",
    "        score = zA.mean() - zB.mean()\n",
    "        if abs(score) < eps:\n",
    "            label = 'Uncertain'\n",
    "        else:\n",
    "            label = 'A' if score < 0 else 'B'\n",
    "        confidence = abs(score) / (np.std(np.concatenate([zA, zB])) + 1e-12)\n",
    "        return label, confidence, score, None\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f'Unknown method: {method}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04451f28",
   "metadata": {},
   "source": [
    "## 7) Run classification over stitched paths directory\n",
    "Update the paths below to the directory containing your stitched `<id>.xtc` files and the associated topology. The code will iterate, extract features, and classify each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Template features not found in namespace.\n",
      "Please load templates first (see cell above):\n",
      "  - tA_feats should combine both pathway A templates (A1 + A2)\n",
      "  - tB_feats should contain pathway B template\n"
     ]
    }
   ],
   "source": [
    "# Directory containing stitched path XTCs (each named like 144.xtc)\n",
    "stitched_dir = Path('load')  # update to your base load dir if needed\n",
    "topology = '/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/trypsin-benzos/gromacs_input_latest/conf.gro'  # update to local copied topology if GVFS paths are used\n",
    "\n",
    "# Choose classification method:\n",
    "# 'auto' - automatically picks best method based on number of frames (RECOMMENDED)\n",
    "# 'statistics' - feature statistics (best for 2-3 frames)\n",
    "# 'voting' - per-frame voting (good for 2-10 frames)\n",
    "# 'endpoint' - start/end comparison (good for PPTIS)\n",
    "# 'dtw' - Dynamic Time Warping (only for >10 frames)\n",
    "classification_method = 'auto'  # Recommended for mixed trajectory lengths\n",
    "\n",
    "# If you haven't loaded templates, stop here and create tA_feats / tB_feats first\n",
    "if 'tA_feats' not in globals() or 'tB_feats' not in globals():\n",
    "    print('‚ö†Ô∏è  Template features not found in namespace.')\n",
    "    print('Please load templates first (see cell above):')\n",
    "    print('  - tA_feats should combine both pathway A templates (A1 + A2)')\n",
    "    print('  - tB_feats should contain pathway B template')\n",
    "else:\n",
    "    results = []\n",
    "    files = sorted([p for p in stitched_dir.glob('*.xtc')])\n",
    "    \n",
    "    # Track method usage statistics\n",
    "    method_counts = {}\n",
    "    \n",
    "    print(f\"Processing {len(files)} trajectory files...\")\n",
    "    print(f\"Using pathway residues:\")\n",
    "    print(f\"  A: {pathway_A_residues if 'pathway_A_residues' in globals() else 'NOT DEFINED'}\")\n",
    "    print(f\"  B: {pathway_B_residues if 'pathway_B_residues' in globals() else 'NOT DEFINED'}\")\n",
    "    print(f\"  H-bond residue: {asp189_resid if 'asp189_resid' in globals() else 189}\")\n",
    "    print()\n",
    "    \n",
    "    for idx, f in enumerate(files, 1):\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"  Processing {idx}/{len(files)}...\")\n",
    "        \n",
    "        try:\n",
    "            u = mda.Universe(topology, str(f))\n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Could not open {f}: {e}')\n",
    "            continue\n",
    "        \n",
    "        n_frames = len(u.trajectory)\n",
    "        \n",
    "        # Extract features with your specific pathway residues\n",
    "        frames, feats = extract_features(\n",
    "            u, \n",
    "            pathway_A_resids=pathway_A_residues if 'pathway_A_residues' in globals() else None,\n",
    "            pathway_B_resids=pathway_B_residues if 'pathway_B_residues' in globals() else None,\n",
    "            hbond_resid=asp189_resid if 'asp189_resid' in globals() else 189\n",
    "        )\n",
    "        \n",
    "        # Standardize features to handle different scales (distances vs angles vs counts)\n",
    "        scaler = StandardScaler()\n",
    "        if feats.size == 0:\n",
    "            print(f'‚ö†Ô∏è  No frames for {f} - skipping')\n",
    "            continue\n",
    "        feats_scaled = scaler.fit_transform(feats)\n",
    "        \n",
    "        # Classify using selected method (auto-selects based on frame count)\n",
    "        try:\n",
    "            label, confidence, dA, dB = classify_segment(\n",
    "                feats_scaled, \n",
    "                scaler.transform(tA_feats), \n",
    "                scaler.transform(tB_feats), \n",
    "                method=classification_method\n",
    "            )\n",
    "            \n",
    "            # Determine which method was actually used (for auto mode)\n",
    "            if classification_method == 'auto':\n",
    "                if n_frames <= 3:\n",
    "                    used_method = 'statistics'\n",
    "                elif n_frames <= 10:\n",
    "                    used_method = 'voting'\n",
    "                else:\n",
    "                    used_method = 'dtw'\n",
    "            else:\n",
    "                used_method = classification_method\n",
    "            \n",
    "            method_counts[used_method] = method_counts.get(used_method, 0) + 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Classification failed for {f}: {e}')\n",
    "            label, confidence, dA, dB = ('Error', 0.0, None, None)\n",
    "            used_method = 'error'\n",
    "        \n",
    "        results.append({\n",
    "            'file': str(f), \n",
    "            'n_frames': n_frames,\n",
    "            'method': used_method,\n",
    "            'label': label, \n",
    "            'confidence': confidence, \n",
    "            'dA': dA, \n",
    "            'dB': dB\n",
    "        })\n",
    "    \n",
    "    # Save results to CSV\n",
    "    out_csv = 'classification_results.csv'\n",
    "    with open(out_csv, 'w', newline='') as fh:\n",
    "        w = csv.DictWriter(fh, fieldnames=list(results[0].keys()))\n",
    "        w.writeheader()\n",
    "        w.writerows(results)\n",
    "    \n",
    "    print(f'\\n‚úì Saved results to {out_csv}')\n",
    "    print(f'\\nüìä Classification summary:')\n",
    "    print(f'  Total trajectories: {len(results)}')\n",
    "    print(f'  Methods used: {method_counts}')\n",
    "    print(f'  Label distribution:')\n",
    "    print(f'    Pathway A: {sum(1 for r in results if r[\"label\"]==\"A\")}')\n",
    "    print(f'    Pathway B: {sum(1 for r in results if r[\"label\"]==\"B\")}')\n",
    "    print(f'    Uncertain: {sum(1 for r in results if r[\"label\"]==\"Uncertain\")}')\n",
    "    print(f'    Errors: {sum(1 for r in results if r[\"label\"]==\"Error\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d184f689",
   "metadata": {},
   "source": [
    "## 8) Quick plotting utilities (examples)\n",
    "Plot a single segment and overlay template(s) to visually inspect classification quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9abfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_com_series(frames, feats, label=None, ax=None):\n",
    "    \"\"\"\n",
    "    Plot ligand-pocket COM distance vs frame index.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    frames : array, frame indices (0-based)\n",
    "    feats : array (T x F), feature matrix where first column is COM distance\n",
    "    label : str, optional label for the plot\n",
    "    ax : matplotlib axis, optional existing axis to plot on\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6,3))\n",
    "    ax.plot(frames, feats[:,0], label=label)\n",
    "    ax.set_xlabel('Frame index')\n",
    "    ax.set_ylabel('Lig-pocket COM (nm)')\n",
    "    return ax\n",
    "\n",
    "# Example: plot first file and templates (if available)\n",
    "# if files:\n",
    "#     f = files[0]\n",
    "#     u = mda.Universe(topology, str(f))\n",
    "#     frames, feats = extract_features(u, \n",
    "#                                      pathway_A_resids=pathway_A_residues,\n",
    "#                                      pathway_B_resids=pathway_B_residues)\n",
    "#     ax = plot_com_series(frames, feats, label=str(f))\n",
    "#     if 'tA_feats' in globals():\n",
    "#         plot_com_series(tA_times, tA_feats, label='template A', ax=ax)\n",
    "#     if 'tB_feats' in globals():\n",
    "#         plot_com_series(tB_times, tB_feats, label='template B', ax=ax)\n",
    "#     ax.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7df5f9",
   "metadata": {},
   "source": [
    "## 9) Notes, pitfalls and next steps\n",
    "- DTW is robust to speed differences but will still be affected by severe undersampling; consider interpolation when templates are much denser.\n",
    "- Standardize features before comparing to reduce units effect.\n",
    "- Tune `contact_cutoff` and DTW `window` for your system; start with small values and inspect results visually.\n",
    "- If you have many segments and performance becomes an issue, compute a low-dimensional projection (PCA) of features and run DTW on the first 2-3 components.\n",
    "- Validate classification by visual inspection on a small labeled subset, or by cross-checking with committor/other physical markers if available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pastime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
