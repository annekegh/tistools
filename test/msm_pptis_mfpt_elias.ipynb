{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib qt   # doesn't work on my laptop\n",
    "from tistools import read_inputfile, get_LMR_interfaces, read_pathensemble, get_weights\n",
    "from tistools import set_tau_distrib, set_tau_first_hit_M_distrib, cross_dist_distr, pathlength_distr\n",
    "from tistools import ACCFLAGS, REJFLAGS\n",
    "\n",
    "from tistools import get_lmr_masks, get_generation_mask, get_flag_mask\n",
    "from tistools import unwrap_by_weight, running_avg_local_probs, get_local_probs, get_globall_probs, get_global_probz\n",
    "\n",
    "from pprint import pprint    # to print the vars of the pathensemble object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2   # something with pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_minus_one = True if lambda_-1 interface is set\n",
    "# zero_minus_one = False if lambda_-1 interface is not set\n",
    "\n",
    "# data the maze\n",
    "#---------------\n",
    "indir = \"/Users/an/Documents/0_mfpt/repptis2/\"\n",
    "zero_minus_one = True\n",
    "inputfile = indir + \"/out.rst\"\n",
    "#inputfile = indir + \"/retis.rst\"\n",
    "\n",
    "# new data Elias\n",
    "#---------------\n",
    "# indir = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/HPC/flat_w-walls/browian-gamma5/100k-cycles/REPPTIS\"\n",
    "# indir = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/HPC/flat_w-walls/newtonian/REPPTIS\"\n",
    "# indir = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/HPC/flat_w-walls/dt-0.00002/REPPTIS\"\n",
    "# indir = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/HPC/cosbump3-walls/REPPTIS\"\n",
    "# indir = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/HPC/cosdip2-walls/REPPTIS\"\n",
    "# indir = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/HPC/cosbumpmeta-walls/REPPTIS\"\n",
    "# indir = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/HPC/cosdipmeta-walls/REPPTIS\"\n",
    "# indir = \"/mnt/0bf0c339-34bb-4500-a5fb-f3c2a863de29/DATA/MSM-REPPTIS/2D-experiments/2D-maze/Wouter-2022/repptis3\"\n",
    "zero_minus_one = False\n",
    "inputfile = indir + \"/out.rst\"\n",
    "\n",
    "# old data bump An\n",
    "#------------------\n",
    "#indir = \"/Users/an/wwork/current-work/0_TitusEnrico/repp/1D-flat.ppr-Febr6-2022d/\"\n",
    "##indir = \"/Users/an/wwork/current-work/0_TitusEnrico/repp/bump-ppretis/\"\n",
    "#inputfile = indir + \"/out.rst\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "os.chdir(indir)\n",
    "print(os.getcwd())\n",
    "\n",
    "folders = glob.glob(indir + \"/0[0-9][0-9]\")\n",
    "folders = sorted(folders)\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! last lines !!!  allow to speed up this notebook\n",
    "# pe.set_orders(load=False...)  -> 1st time you run the code, this will store npy files\n",
    "# pe.set_orders(load=True...)  -> next time you run the code, you can read npy files\n",
    "\n",
    "# Reading all input\n",
    "#===================\n",
    "interfaces, zero_left, timestep = read_inputfile(inputfile)\n",
    "LMR_interfaces, LMR_strings = get_LMR_interfaces(interfaces, zero_left)\n",
    "pathensembles = []\n",
    "for i,fol in enumerate(folders):\n",
    "    print(\"#\"*80)\n",
    "    print(fol)\n",
    "    pe = read_pathensemble(fol+\"/pathensemble.txt\")\n",
    "    pe.set_name(fol)\n",
    "    pe.set_interfaces([LMR_interfaces[i], LMR_strings[i]])\n",
    "    if i==0:\n",
    "        pe.set_zero_minus_one(zero_minus_one)   # TODO this is never used\n",
    "        pe.set_in_zero_minus(True)\n",
    "    if i==1:\n",
    "        pe.set_in_zero_plus(True)\n",
    "    w, _ = get_weights(pe.flags, ACCFLAGS, REJFLAGS, verbose = False)\n",
    "    pe.set_weights(w)\n",
    "    print(\"pathensemble info: \")\n",
    "    pprint(vars(pe))\n",
    "    pathensembles.append(pe)\n",
    "    # read order parameters order.txt/order.npy into path ensemble object\n",
    "    #pe.set_orders(load=False, acc_only=True, save=False) # if saving doesn't work\n",
    "    #### CHANGE HERE ####\n",
    "    # pe.set_orders(load=False, acc_only=True, save=True) # for the 1st time\n",
    "    pe.set_orders(load=True, acc_only=True) # for the next times, save=True/False is not important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path ensemble properties\n",
    "#==================================\n",
    "for i,fol in enumerate(folders):\n",
    "    print(i)\n",
    "    if i != 1:\n",
    "        print(\"Calculating path lengths.\")\n",
    "        set_tau_distrib(pathensembles[i])\n",
    "        print(\"Done.\")\n",
    "    #else:\n",
    "        #TODO problem with ...\n",
    "    if i > 1:\n",
    "        print(\"Calculating first hitting lengths to middle interface\")\n",
    "        set_tau_first_hit_M_distrib(pathensembles[i])\n",
    "        print(\"Done.\")\n",
    "    #else:\n",
    "        # TODO problem with ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the pptis simulation.\n",
    "# Analysis output is saved to the data dictionary.\n",
    "data = {}\n",
    "for i, pe in enumerate(pathensembles):\n",
    "    print(\"doing pathensemble {}\".format(i))\n",
    "    if i == 0:\n",
    "        data[i] = {}\n",
    "        continue  # TODO: make [0-] analysis ???\n",
    "\n",
    "    # masks - TODO not used further on?\n",
    "    # TODO these functions are duplicate in repptis_analysis\n",
    "    #masks = get_lmr_masks(pe)\n",
    "    #loadmask = get_generation_mask(pe, \"ld\")\n",
    "    #print(\"Amount of loads: {}\".format(np.sum(loadmask)))\n",
    "    ##hardloadmask = get_hard_load_mask(loadmask)\n",
    "    #accmask = get_flag_mask(pe, \"ACC\")\n",
    "\n",
    "    # pathtype_cycles\n",
    "    pathtypes = (\"LML\", \"LMR\", \"RML\", \"RMR\")\n",
    "    pathtype_cycles = {}\n",
    "    for ptype in pathtypes:\n",
    "        pathtype_cycles[ptype] = unwrap_by_weight(\n",
    "                (pe.lmrs == ptype).astype(int), pe.weights)\n",
    "    \n",
    "    # running average analysis: [\"running\"]\n",
    "    data[i] = {}\n",
    "    data[i][\"running\"] = {}\n",
    "    data[i][\"running\"][\"plocal\"] = {}\n",
    "    # you'll still have to hardload select pe.weigths... TODO. # this is comment wouter?\n",
    "    for (ptype, p_loc) in zip(pathtypes, \n",
    "                              running_avg_local_probs(pathtype_cycles, \n",
    "                                                      pe.weights, tr = False)):\n",
    "        data[i][\"running\"][\"plocal\"][ptype] = p_loc\n",
    "\n",
    "    # analysis using all data: [\"full\"]\n",
    "    plocfull = get_local_probs(pe, tr=False)\n",
    "    data[i][\"full\"] = {}\n",
    "    for ptype in pathtypes:\n",
    "        data[i][\"full\"][ptype] = plocfull[ptype]\n",
    "\n",
    "    # data[i] have now [\"full\"] and [\"running\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, pe in enumerate(pathensembles):\n",
    "    upe = pe.unify_pe()\n",
    "    # Pathlength distribution\n",
    "    data[i][\"pathlengths\"] = pathlength_distr(upe)  # these might be used later or not! TODO\n",
    "        \n",
    "#=======================================\n",
    "# make figures\n",
    "makefigs = True \n",
    "if makefigs:\n",
    "    for i, pe in enumerate(pathensembles):     \n",
    "        if i == 0:\n",
    "            continue\n",
    "        # Cross distances distribution\n",
    "        L, M, R, lmlpercs, lmllambs, rmrpercs, rmrlambs = cross_dist_distr(pe)\n",
    "        fig,ax = plt.subplots()\n",
    "        ax.plot(lmllambs, lmlpercs, lw=1, c=\"g\")\n",
    "        ax.plot(rmrlambs, rmrpercs, lw=1, c=\"r\")\n",
    "        for lamb in (L,M,R):\n",
    "            ax.axvline(lamb, color='k', linestyle='--', lw = 0.5)\n",
    "        ax.set_xlabel('Cross distance')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(\"Ensemble {}. L = {}, M = {}, R = {}\".format(\n",
    "            pe.name, L, M, R))\n",
    "        ax.set_ylim(0)\n",
    "        fig.savefig(f\"pathensemble_{i}_crossdist.pdf\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Pathlength distribution      \n",
    "        for ptype in pathtypes:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(data[i][\"pathlengths\"][ptype][\"bin_centers\"], \n",
    "                data[i][\"pathlengths\"][ptype][\"hist\"])\n",
    "            ax.set_xlabel('Pathlength')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_title(f\"{np.sum(data[i]['pathlengths'][ptype]['hist'])} \" + \\\n",
    "                         f\"{ptype} paths. \")\n",
    "            ax.legend([f\"mean = {data[i]['pathlengths'][ptype]['mean']:.2f}, \" + \\\n",
    "                          f\"std = {data[i]['pathlengths'][ptype]['std']:.2f}\"])\n",
    "            fig.savefig(f\"pathensemble_{i}_pathlength_{ptype}.pdf\")\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pcross with recursive relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global crossing probabilities\n",
    "# WITHOUT ERRORS #  \n",
    "# Full data \n",
    "psfull = []\n",
    "for i in range(1, len(pathensembles)):   # do not use the 0- ensemble\n",
    "    psfull.append({\"LMR\": data[i][\"full\"][\"LMR\"], \n",
    "               \"RML\": data[i][\"full\"][\"RML\"], \n",
    "               \"RMR\": data[i][\"full\"][\"RMR\"],\n",
    "               \"LML\": data[i][\"full\"][\"LML\"]})\n",
    "\n",
    "Pminfull, Pplusfull, Pcrossfull = get_globall_probs(psfull)\n",
    "print(Pcrossfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a figure of the global crossing probabilities\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale(\"log\")\n",
    "ax.plot(Pcrossfull, \"o\", c = \"r\")\n",
    "\n",
    "# cosdip meta\n",
    "# ax.errorbar([i for i in range(7)], Pcrossfull, yerr=[0, 0.004830, Pcrossfull[2]*0.05068988646, Pcrossfull[3]*0.05189862680, Pcrossfull[4]*0.05071184896, Pcrossfull[5]*0.05083284286, Pcrossfull[6]*0.05067963543], fmt=\"-o\", c = \"b\", ecolor=\"r\", capsize=6)\n",
    "\n",
    "# cosbump meta\n",
    "# ax.errorbar([i for i in range(7)], Pcrossfull, yerr=[0, 0.002535, Pcrossfull[2]*0.04393065503, Pcrossfull[3]*0.04910273500, Pcrossfull[4]*0.05239942040, Pcrossfull[5]*0.05789033634, Pcrossfull[6]*0.0614468], fmt=\"-o\", c = \"b\", ecolor=\"r\", capsize=6)\n",
    "\n",
    "# 2 cosdips\n",
    "# ax.errorbar([i for i in range(5)], Pcrossfull, yerr=[0, 0.007239, Pcrossfull[2]*0.0414296, Pcrossfull[3]*0.0445266, Pcrossfull[4]*0.0483538], fmt=\"-o\", c = \"b\", ecolor=\"r\", capsize=6)\n",
    "\n",
    "# 3 cosbumps\n",
    "# ax.errorbar([i for i in range(7)], Pcrossfull, yerr=[0, 0.002295, Pcrossfull[2]*0.0328798, Pcrossfull[3]*0.031594, Pcrossfull[4]*0.031474, Pcrossfull[5]*0.03080392, Pcrossfull[6]*0.0308589], fmt=\"-o\", c = \"b\", ecolor=\"r\", capsize=6)\n",
    "\n",
    "# 2 cosbumps\n",
    "#ax.errorbar([i for i in range(5)], Pcrossfull, yerr=[0, 0.002768, Pcrossfull[2]*0.04440278, Pcrossfull[3]*0.043053, Pcrossfull[4]*0.0463156], fmt=\"-o\", c = \"b\", ecolor=\"r\", capsize=6)\n",
    "\n",
    "# flat dt=0.00002 30k cycles\n",
    "# ax.errorbar([i for i in range(5)], Pcrossfull, yerr=[0, 0.003294, Pcrossfull[2]*0.07640968, Pcrossfull[3]*0.07789262, Pcrossfull[4]*0.0812692], fmt=\"-o\", c = \"b\", ecolor=\"r\", capsize=6)\n",
    "\n",
    "# flat 100k cycles\n",
    "#ax.errorbar([i for i in range(5)], Pcrossfull, yerr=[0, 0.002741, Pcrossfull[2]*0.034092, Pcrossfull[3]*0.033621, Pcrossfull[4]*0.0398], fmt=\"-o\", c = \"b\", ecolor=\"r\", capsize=6)\n",
    "ax.set_xlabel(\"intf\")\n",
    "ax.set_ylabel(r\"$P_A(\\lambda_i|\\lambda_A)$\")\n",
    "ax.set_xticks(np.arange(len(interfaces)))\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(\"Global_probs.pdf\")\n",
    "\n",
    "print(\"This should be the same as the repptis_report.pdf value:\", Pcrossfull[-1])\n",
    "print(\"which is the case!\")\n",
    "print(\"Here, the load immediately disappeared. For a simulation where this is\")\n",
    "print(\"not the case, the above code should be adapted a little bit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO I am not sure what this is\n",
    "\n",
    "# Construct lists of the local probs\n",
    "\n",
    "# Or we can use the get_global_probz function, using lists of the local probs\n",
    "# These do not use the 0- ensemble\n",
    "pmps = [data[i][\"full\"][\"LMR\"] for i in range(1,len(pathensembles))]\n",
    "pmms = [data[i][\"full\"][\"LML\"] for i in range(1,len(pathensembles))]\n",
    "ppps = [data[i][\"full\"][\"RMR\"] for i in range(1,len(pathensembles))]\n",
    "ppms = [data[i][\"full\"][\"RML\"] for i in range(1,len(pathensembles))]\n",
    "a,b,c = get_global_probz(pmps, pmms, ppps, ppms)\n",
    "print(\"This should be the same as the repptis_report.pdf value:\", c[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now work with MSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tistools import construct_M\n",
    "from tistools import global_cross_prob\n",
    "from tistools import vector_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels_states(N):\n",
    "    assert N>=3\n",
    "    labels1 = [\"0-     \",\"B      \"]\n",
    "    labels2 = [\"0+- LML\",\"0+- LMR\",\"0+- RML\",\"1+- LML\",\"1+- LMR\"]\n",
    "    if N>3:\n",
    "        for i in range(1,N-2):\n",
    "            labels2.append(str(i)  +\"+- RML\")\n",
    "            labels2.append(str(i)  +\"+- RMR\")\n",
    "            labels2.append(str(i+1)+\"+- LML\")\n",
    "            labels2.append(str(i+1)+\"+- LMR\")\n",
    "    return labels1, labels2\n",
    "\n",
    "def print_vector(g, states=None):\n",
    "    if states is None:\n",
    "        for i in range(len(g)):\n",
    "            print(\"state\", i, g[i])\n",
    "    else:\n",
    "        for i in range(len(g)):\n",
    "            print(\"state\", states[i], g[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interfaces)\n",
    "N = len(interfaces)\n",
    "assert N >= 4\n",
    "NS = 4*N-5\n",
    "print(\"N\", N)\n",
    "print(\"len pmms\", len(pmms))\n",
    "print(\"NS\", NS)\n",
    "\n",
    "#labels2 = [\"0+- LML\",\"0+- LMR\",\"0+- RML\",\"1+- LML\",\"1+- LMR\",\n",
    "#           \"1+- RML\", \"1+- RMR\", \"2+- LML\", \"2+- LMR\",\n",
    "#           \"2+- RML\", \"2+- RMR\", \"3+- LML\", \"3+- LMR\",]\n",
    "labels1, labels2 = create_labels_states(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mm\", pmms)\n",
    "print(\"mp\", pmps)\n",
    "print(\"pm\", ppms)\n",
    "print(\"pp\", ppps)\n",
    "print(\"sum\", np.array(pmms)+np.array(pmps))\n",
    "print(\"sum\", np.array(ppms)+np.array(ppps))\n",
    "M = construct_M(pmms, pmps, ppms, ppps, NS, N)\n",
    "\n",
    "#Local crossing probabilities:\n",
    "#pRMR = 0.34205627942625644.  #ppps\n",
    "#pRML = 0.6579437205737436.   #ppms\n",
    "#pLMR = 0.25316455696202533.  #pmps\n",
    "#pLML = 0.7468354430379747.   #pmms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"M\")\n",
    "print(\"shape\", M.shape)\n",
    "print(\"sum prob in rows\", np.sum(M,axis=1))\n",
    "print(M)\n",
    "# row 8, 10, 12, 14. # counting starts from 0   not okay!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at this Markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy.linalg\n",
    "vals, vecs = np.linalg.eig(M)\n",
    "print(vals)\n",
    "vals, vecs = np.linalg.eig(M.T)\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"what if chain propagates\")\n",
    "print(\"A[0,:]\")\n",
    "# check stationary behavior\n",
    "A = M\n",
    "for n in range(10):\n",
    "    A = np.dot(A,M)\n",
    "    #print(A)\n",
    "    print(A[0,:])\n",
    "    print(np.sum(A[0,:]))  # is 1 indeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pcross with MSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global crossing prob\n",
    "z1, z2, y1, y2 = global_cross_prob(M)\n",
    "print(\"Z\")\n",
    "print_vector(z1, labels1)\n",
    "print_vector(z2, labels2)\n",
    "print(\"Y\")\n",
    "print_vector(y1, labels1)\n",
    "print_vector(y2, labels2)\n",
    "print(\"global crossing prob\", y1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO I need data too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tau(pathensembles, data):\n",
    "    # pathensembles -- list of pathensemble instances\n",
    "    \n",
    "    print(\"Collect tau\")\n",
    "    \n",
    "    # average path lengths\n",
    "    taumm = np.zeros(len(pathensembles))\n",
    "    taump = np.zeros(len(pathensembles))\n",
    "    taupm = np.zeros(len(pathensembles))\n",
    "    taupp = np.zeros(len(pathensembles))\n",
    "    \n",
    "    # for [1+-] and higher (i>=2)\n",
    "    for i in range(2,len(pathensembles)):\n",
    "        print(\"ensemble\", i, pathensembles[i].name)\n",
    "        taumm[i] = pathensembles[i].tauavg['LML']-2\n",
    "        taump[i] = pathensembles[i].tauavg['LMR']-2\n",
    "        taupm[i] = pathensembles[i].tauavg['RML']-2\n",
    "        taupp[i] = pathensembles[i].tauavg['RMR']-2\n",
    "\n",
    "    # for [0-] (i=0)\n",
    "    print(\"ensemble\", 0, pathensembles[0].name)\n",
    "    if pe.has_zero_minus_one:\n",
    "        # TODO pieces missing\n",
    "        taumm[0] = pathensembles[0].tauavg['LML']-2\n",
    "        taump[0] = pathensembles[0].tauavg['LMR']-2\n",
    "        taupm[0] = pathensembles[0].tauavg['RML']-2\n",
    "        taupp[0] = pathensembles[0].tauavg['RMR']-2\n",
    "    else:\n",
    "        taupp[0] = pathensembles[0].tauavg['RMR']-2\n",
    "\n",
    "    # for [0+-] (i=1)\n",
    "    print(\"ensemble\", 1, pathensembles[1].name)\n",
    "    taumm[1] = data[1][\"pathlengths\"][\"LML\"][\"mean\"] - 2\n",
    "    taump[1] = data[1][\"pathlengths\"][\"LMR\"][\"mean\"] - 2\n",
    "    taupm[1] = data[1][\"pathlengths\"][\"RML\"][\"mean\"] - 2\n",
    "    #taupp[1] = data[1][\"pathlengths\"][\"RMR\"][\"mean\"] - 2\n",
    "\n",
    "    return taumm, taump, taupm, taupp\n",
    "\n",
    "# this is the same:\n",
    "# 1) after:\n",
    "#   data[2][\"pathlengths\"] = pathlength_distr(upe)  # use correct upe!\n",
    "#   This gives the whole distrib, mean, std, etc\n",
    "#   print(data[2][\"pathlengths\"][\"RMR\"][\"mean\"])\n",
    "# 2) after:\n",
    "#   set_tau_distrib(pathensembles[2])\n",
    "#   print(pathensembles[2].tauavg['RMR'])\n",
    "\n",
    "# TODO for [0-]\n",
    "# likely not okay yet, what about L*L etc??????\n",
    "# There are paths missing TODO!!!!!!!! when lambda-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO fix +-1 issues!!!!!!\n",
    "# TODO tau1 is not fool proof if you have too many phase points!!\n",
    "\n",
    "def collect_tau1(pathensembles, data):\n",
    "    # average path lengths, but only the part before the 1st crossing\n",
    "    #---------------------------\n",
    "    print(\"Collect tau1\")\n",
    "    taumm1 = np.zeros(len(pathensembles))\n",
    "    taump1 = np.zeros(len(pathensembles))\n",
    "    taupm1 = np.zeros(len(pathensembles))\n",
    "    taupp1 = np.zeros(len(pathensembles))\n",
    "    \n",
    "    # for [1+-] and higher (i>=2)\n",
    "    for i in range(2,len(pathensembles)):\n",
    "        taumm1[i] = pathensembles[i].tau1avg['LML'] - 1\n",
    "        taump1[i] = pathensembles[i].tau1avg['LMR'] - 1\n",
    "        taupm1[i] = pathensembles[i].tau1avg['RML'] - 1\n",
    "        taupp1[i] = pathensembles[i].tau1avg['RMR'] - 1\n",
    "    # for [0-] (i=0) -> just 0\n",
    "    # for [0+-] (i=1) LML -> just 0\n",
    "    # for [0+-] (i=1) LMR -> just 0\n",
    "    # for [0+-] (i=1) RML\n",
    "    taupm1[1] = data[1][\"pathlengths\"][\"RML\"][\"mean\"] - 2\n",
    "    \n",
    "    return taumm1, taump1, taupm1, taupp1\n",
    "\n",
    "def collect_tau2(pathensembles, data):\n",
    "    # average path lengths, but only the part after the last crossing\n",
    "    #---------------------------\n",
    "    print(\"Collect tau2\")\n",
    "    taumm2 = np.zeros(len(pathensembles))\n",
    "    taump2 = np.zeros(len(pathensembles))\n",
    "    taupm2 = np.zeros(len(pathensembles))\n",
    "    taupp2 = np.zeros(len(pathensembles))\n",
    "    \n",
    "    # for [1+-] and higher (i>=2)\n",
    "    for i in range(2,len(pathensembles)):\n",
    "        taumm2[i] = pathensembles[i].tau2avg['LML'] - 1\n",
    "        taump2[i] = pathensembles[i].tau2avg['LMR'] - 1\n",
    "        taupm2[i] = pathensembles[i].tau2avg['RML'] - 1\n",
    "        taupp2[i] = pathensembles[i].tau2avg['RMR'] - 1\n",
    "    # for [0-] (i=0) -> just 0\n",
    "    # for [0+-] (i=1) LML -> just 0\n",
    "    # for [0+-] (i=1) LMR\n",
    "    taump2[1] = data[1][\"pathlengths\"][\"LMR\"][\"mean\"] - 2\n",
    "    # for [0+-] (i=1) RML -> just 0\n",
    "    \n",
    "    return taumm2, taump2, taupm2, taupp2\n",
    "\n",
    "def collect_taum(pathensembles, data):\n",
    "    # average path lengths, but only the part between first/last crossing\n",
    "    #---------------------------\n",
    "    print(\"Collect taum\")\n",
    "    taumm_m = np.zeros(len(pathensembles))\n",
    "    taump_m = np.zeros(len(pathensembles))\n",
    "    taupm_m = np.zeros(len(pathensembles))\n",
    "    taupp_m = np.zeros(len(pathensembles))\n",
    "    \n",
    "    # for [1+-] and higher (i>=2)\n",
    "    for i in range(2,len(pathensembles)):\n",
    "        #print(\"ensemble\", i, pathensembles[i].name)\n",
    "        taumm_m[i] = pathensembles[i].tauavg['LML'] \\\n",
    "                   - pathensembles[i].tau1avg['LML'] \\\n",
    "                   - pathensembles[i].tau2avg['LML']\n",
    "        taump_m[i] = pathensembles[i].tauavg['LMR'] \\\n",
    "                   - pathensembles[i].tau1avg['LMR'] \\\n",
    "                   - pathensembles[i].tau2avg['LMR']\n",
    "        taupm_m[i] = pathensembles[i].tauavg['RML'] \\\n",
    "                   - pathensembles[i].tau1avg['RML'] \\\n",
    "                   - pathensembles[i].tau2avg['RML']\n",
    "        taupp_m[i] = pathensembles[i].tauavg['RMR'] \\\n",
    "                   - pathensembles[i].tau1avg['RMR'] \\\n",
    "                   - pathensembles[i].tau2avg['RMR']\n",
    "\n",
    "    # for [0-] (i=0)\n",
    "    if pe.has_zero_minus_one:\n",
    "        # TODO there are more paths!!!\n",
    "        taumm_m[0] = pathensembles[0].tauavg['LML']-2\n",
    "        taump_m[0] = pathensembles[0].tauavg['LMR']-2\n",
    "        taupm_m[0] = pathensembles[0].tauavg['RML']-2\n",
    "        taupp_m[0] = pathensembles[0].tauavg['RMR']-2\n",
    "    else:\n",
    "        taupp_m[0] = pathensembles[0].tauavg['RMR']-2\n",
    "\n",
    "    # for [0+-] (i=1) LML\n",
    "    taumm_m[1] = data[1][\"pathlengths\"][\"LML\"][\"mean\"] - 2\n",
    "    # for [0+-] (i=1) LMR -> just 0\n",
    "    # for [0+-] (i=1) RML -> just 0\n",
    "\n",
    "    return taumm_m, taump_m, taupm_m, taupp_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_tau(pathensembles, taumm, taump, taupm, taupp):\n",
    "    # print all tau\n",
    "    print(f\"                  mm            mp            pm            pp\")\n",
    "    for i in range(len(pathensembles)):\n",
    "        print(f\"{i} {pathensembles[i].name[-3:]}  {taumm[i]:13.1f} {taump[i]:13.1f} {taupm[i]:13.1f} {taupp[i]:13.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taumm, taump, taupm, taupp = collect_tau(pathensembles, data)\n",
    "taumm1, taump1, taupm1, taupp1 = collect_tau1(pathensembles, data)\n",
    "taumm2, taump2, taupm2, taupp2 = collect_tau2(pathensembles, data)\n",
    "taumm_m, taump_m, taupm_m, taupp_m = collect_taum(pathensembles, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tau\")\n",
    "print_all_tau(pathensembles, taumm, taump, taupm, taupp)\n",
    "print(\"\\ntau1\")\n",
    "print_all_tau(pathensembles, taumm1, taump1, taupm1, taupp1)\n",
    "print(\"\\ntau_m\")\n",
    "print_all_tau(pathensembles, taumm_m, taump_m, taupm_m, taupp_m)\n",
    "print(\"\\ntau2\")\n",
    "print_all_tau(pathensembles, taumm2, taump2, taupm2, taupp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tau_vector(N, NS, taumm, taump, taupm, taupp):\n",
    "    assert N>=4\n",
    "    assert NS==4*N-5\n",
    "    assert len(taumm) == N\n",
    "    assert len(taump) == N\n",
    "    assert len(taupm) == N\n",
    "    assert len(taupp) == N\n",
    "    # unravel the values into one vector\n",
    "    tau = np.zeros(NS)\n",
    "    # [0-]\n",
    "    tau[0] = taupp[0]\n",
    "    # [0+-]\n",
    "    tau[1] = taumm[1]\n",
    "    tau[2] = taump[1]\n",
    "    tau[3] = taupm[1]\n",
    "    # [1+-] etc\n",
    "    for i in range(1,N-2):\n",
    "        tau[4*i]   = taumm[i+1]\n",
    "        tau[4*i+1] = taump[i+1]\n",
    "        tau[4*i+2] = taupm[i+1]\n",
    "        tau[4*i+3] = taupp[i+1]\n",
    "    # [(N-2)^(-1)]\n",
    "    tau[-3] = taumm[-1]\n",
    "    tau[-2] = taump[-1]\n",
    "    # B\n",
    "    tau[-1] = 0.   # whatever\n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tau  = construct_tau_vector(N, NS, taumm, taump, taupm, taupp)\n",
    "tau1 = construct_tau_vector(N, NS, taumm1, taump1, taupm1, taupp1)\n",
    "taum = construct_tau_vector(N, NS, taumm_m, taump_m, taupm_m, taupp_m)\n",
    "tau2 = construct_tau_vector(N, NS, taumm2, taump2, taupm2, taupp2)\n",
    "tau_m = tau-tau1-tau2  # yes, this is the same thing\n",
    "\n",
    "print(\"tau\")\n",
    "print(tau)\n",
    "print(\"\\n\")\n",
    "print(\"tau1\")\n",
    "print(tau1)\n",
    "print(\"taum\")\n",
    "print(taum)\n",
    "print(\"tau2\")\n",
    "print(tau2)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"tau = tau1+taum+tau2 => difference is\", np.sum((tau-tau1-taum-tau2)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute tau for [0+]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1, g2, h1, h2 = vector_G(M, tau1, tau_m, tau2) #, doprint=True)\n",
    "print(\"G\")\n",
    "print_vector(g1, labels1)\n",
    "print_vector(g2, labels2)\n",
    "print(\"H\")\n",
    "print_vector(h1, labels1)\n",
    "print_vector(h2, labels2)\n",
    "print(\"interesting\")\n",
    "print(h1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(h1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flux = 1/(tau[0]+h1[0])\n",
    "dt = 0.0002\n",
    "# dt = 0.00002\n",
    "# dt = 0.01\n",
    "flux\n",
    "print(flux/dt, \"1/time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
